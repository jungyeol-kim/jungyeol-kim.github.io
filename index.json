[{"authors":null,"categories":null,"content":"I\u0026rsquo;m a PhD candidate in the department of Electrical and Systems Engineering at the University of Pennsylvania; also pursuing a dual Master\u0026rsquo;s degree in Statistics. My research focuses broadly on modelling and control of dynamic behavior of spreading processes in networked systems using real-world data, with applications in vehicular messaging and epidemic spreading. Before coming to Penn, I obtained my bachelor\u0026rsquo;s and master\u0026rsquo;s degrees in Physics from Korea University and worked as a data scientist at Korea Telecom (KT). My work in industry involved developing anomaly detection model, visualizing data, and providing actionable information in collaborative projects with government clients.\n  Download my resum√©.\n","date":1554595200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1554595200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://jungyeol-kim.github.io/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"I\u0026rsquo;m a PhD candidate in the department of Electrical and Systems Engineering at the University of Pennsylvania; also pursuing a dual Master\u0026rsquo;s degree in Statistics. My research focuses broadly on modelling and control of dynamic behavior of spreading processes in networked systems using real-world data, with applications in vehicular messaging and epidemic spreading.","tags":null,"title":"","type":"authors"},{"authors":null,"categories":null,"content":"Âê≥ÊÅ©ÈÅî is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"da99cb196019cc5857b9b3e950397ca9","permalink":"https://jungyeol-kim.github.io/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"Âê≥ÊÅ©ÈÅî is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"Âê≥ÊÅ©ÈÅî","type":"authors"},{"authors":null,"categories":null,"content":"   Table of Contents    What you will learn Program overview Courses in this program Meet your instructor FAQs      What you will learn  Fundamental Python programming skills Statistical concepts and how to apply them in practice Gain experience with the Scikit, including data visualization with Plotly and data wrangling with Pandas  Program overview The demand for skilled data science practitioners is rapidly growing. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi.\nCourses in this program  Python basics Build a foundation in Python.   Visualization Learn how to visualize data with Plotly.   Statistics Introduction to statistics for data science.   Meet your instructor admin FAQs Are there prerequisites? There are no prerequisites for the first course.\n How often do the courses run? Continuously, at your own pace.\n  Begin the course   ","date":1611446400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1611446400,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://jungyeol-kim.github.io/courses/example/","publishdate":"2021-01-24T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"An example of using Wowchemy's Book layout for publishing online courses.","tags":null,"title":"üìä Learn Data Science","type":"book"},{"authors":null,"categories":null,"content":"Build a foundation in Python.\n  1-2 hours per week, for 8 weeks\nLearn   Quiz What is the difference between lists and tuples? Lists\n Lists are mutable - they can be changed Slower than tuples Syntax: a_list = [1, 2.0, 'Hello world']  Tuples\n Tuples are immutable - they can\u0026rsquo;t be changed Tuples are faster than lists Syntax: a_tuple = (1, 2.0, 'Hello world')   Is Python case-sensitive? Yes\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"17a31b92253d299002593b7491eedeea","permalink":"https://jungyeol-kim.github.io/courses/example/python/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/python/","section":"courses","summary":"Build a foundation in Python.\n","tags":null,"title":"Python basics","type":"book"},{"authors":null,"categories":null,"content":"Learn how to visualize data with Plotly.\n  1-2 hours per week, for 8 weeks\nLearn   Quiz When is a heatmap useful? Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n Write Plotly code to render a bar chart import plotly.express as px data_canada = px.data.gapminder().query(\u0026quot;country == 'Canada'\u0026quot;) fig = px.bar(data_canada, x='year', y='pop') fig.show()  ","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"1b341b3479c8c6b1f807553b77e21b7c","permalink":"https://jungyeol-kim.github.io/courses/example/visualization/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/visualization/","section":"courses","summary":"Learn how to visualize data with Plotly.\n","tags":null,"title":"Visualization","type":"book"},{"authors":null,"categories":null,"content":"Introduction to statistics for data science.\n  1-2 hours per week, for 8 weeks\nLearn The general form of the normal probability density function is:\n$$ f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi} } e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2} $$\n The parameter $\\mu$ is the mean or expectation of the distribution. $\\sigma$ is its standard deviation. The variance of the distribution is $\\sigma^{2}$.   Quiz What is the parameter $\\mu$? The parameter $\\mu$ is the mean or expectation of the distribution.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"6f4078728d71b1b791d39f218bf2bdb1","permalink":"https://jungyeol-kim.github.io/courses/example/stats/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/stats/","section":"courses","summary":"Introduction to statistics for data science.\n","tags":null,"title":"Statistics","type":"book"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://jungyeol-kim.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":null,"categories":["R"],"content":"Agents in complex systems interact in many ways: People are influenced by multiple channels of social interaction such as friendship and work partnership, and multiple means of transportation such as avian and ground transportation constitute the global transportation infrastructure. Such systems can best be represented as multiplex networks with multiple types of links. Each link type in the system defines a network layer, which is by no means in isolation but coexists and cooperates with other layers to fulfill the system‚Äôs function. Such coupling and interplay of network layers can result in emergent structural and dynamical impact in nontrivial ways, rendering the understanding based on the single-network approach incomplete.\nTowards understanding such multiplex systems, we propose a modeling framework based on coevolution of network layers, with a class of minimalistic growing network models as working examples. We examine how the entangled growth of coevolving layers can shape the network structure and show analytically and numerically that the coevolution can induce strong degree correlations across layers, as well as modulate degree distributions. We further show that such a coevolution-induced correlated multiplexity can alter the system‚Äôs response to the dynamical process, exemplified by the suppressed susceptibility to a social cascade process.\n   ","date":1606875194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606875194,"objectID":"68dad3a42395bdaae8161511ba42e601","permalink":"https://jungyeol-kim.github.io/project/multiplex-networks-1/","publishdate":"2020-12-01T21:13:14-05:00","relpermalink":"/project/multiplex-networks-1/","section":"project","summary":"Agents in complex systems interact in many ways: People are influenced by multiple channels of social interaction such as friendship and work partnership, and multiple means of transportation such as avian and ground transportation constitute the global transportation infrastructure.","tags":["R","V2V","Network"],"title":"Coevolution in Multiplex Networks","type":"project"},{"authors":null,"categories":["R"],"content":"Nodes in a complex networked system often engage in more than one type of interactions among them; they form a multiplex network with multiple types of links. In real-world complex systems, a node‚Äôs degree for one type of links and that for the other are not randomly distributed but correlated, which we term correlated multiplexity. In this paper, we study a simple model of multiplex random networks and demonstrate that the correlated multiplexity can drastically affect the properties of a giant component in the network. Specifically, when the degrees of a node for different interactions in a duplex Erdo Ããs‚ÄìRe ÃÅnyi network are maximally correlated, the network contains the giant component for any nonzero link density. In contrast, when the degrees of a node are maximally anti-correlated, the emergence of the giant component is significantly delayed, yet the entire network becomes connected into a single component at a finite link density. We also discuss the mixing patterns and the cases with imperfect correlated multiplexity.\n   ","date":1606875194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606875194,"objectID":"f8bae55da620232190cfb9892dab29bc","permalink":"https://jungyeol-kim.github.io/project/multiplex-networks-2/","publishdate":"2020-12-01T21:13:14-05:00","relpermalink":"/project/multiplex-networks-2/","section":"project","summary":"Nodes in a complex networked system often engage in more than one type of interactions among them; they form a multiplex network with multiple types of links. In real-world complex systems, a node‚Äôs degree for one type of links and that for the other are not randomly distributed but correlated, which we term correlated multiplexity.","tags":["R","V2V","Network"],"title":"Correlated multiplexity and connectivity of multiplex random networks","type":"project"},{"authors":null,"categories":["R"],"content":"One of the types of errors that we are concerned with in Lasso regression is the prediction loss: $ ||X (\\hat{\\beta}-\\beta^{\\star})||^2_2. $ For the model $ Y=X\\beta^{\\star}+\\epsilon $, where $ \\epsilon \\sim \\text{subG}(\\sigma^2) $, the Lasso solution is\n$$ \\hat{\\beta} := \\hat{\\beta}_{Lasso} \\in argmin_{\\beta} \\frac{1}{2n} ||Y-X\\beta||^2 +\\lambda_n ||\\beta||_1. $$ Theorem: Let A be the event {$ \\lambda_n \\geq n^{-1} ||X^T \\epsilon ||_{\\infty} $}. If A holds, then\n$$ MSE(\\hat{\\beta}) = \\frac{||X (\\hat{\\beta}-\\beta^{\\star})||^2}{n} \\leq 4 ||\\beta^{\\star}||_1 \\lambda_n $$\nProof: By the definition of Lasso, we have\n\\begin{align} \\frac{1}{2n} ||Y-X\\hat{\\beta}||_2^2 + \\lambda_n ||\\hat{\\beta}||_1 \\leq \\frac{1}{2n} ||Y-X{\\beta}^{\\star}||^2 + \\lambda_n ||{\\beta}^{\\star}||_1 \\end{align}\nWe use true model equation $ Y=X{\\beta}^{\\star}+\\epsilon $. By substituting $ Y $ for $ X{\\beta}^{\\star}+\\epsilon $, we have\n\\begin{align} \\frac{1}{2n} ||X (\\hat{\\beta}-\\beta^{\\star})||_2^2 \u0026amp; \\leq \\frac{\\epsilon^\\top X (\\hat{\\beta}-\\beta^{\\star})}{n} + \\lambda_n (||\\beta^{\\star}||_1-||\\hat{\\beta}||_1)\\\\\n\u0026amp; (\\text{by Holder\u0026rsquo;s Inequality, }\\epsilon^\\top X (\\hat{\\beta}-\\beta^{\\star}) = |\\sum_{i=1}^{d}(\\epsilon^\\top X)_i (\\hat{\\beta}-\\beta^{\\star})_i| \\leq ||\\epsilon^\\top X||_{\\infty} ||\\hat{\\beta}-\\beta^{\\star}||_1) \\nonumber \\\\ \u0026amp; \\leq \\frac{||\\epsilon^\\top X||_{\\infty} ||\\hat{\\beta}-\\beta^{\\star}||_1}{n} + \\lambda_n(||\\beta^{\\star}||_1-||\\hat{\\beta}||_1)\\\\\n\u0026amp; (\\text{by Triangle Inequality, }||\\hat{\\beta}-\\beta^{\\star}||_1 \\leq ||\\hat{\\beta}||_1 + ||-\\beta^{\\star}||_1 = ||\\hat{\\beta}||_1 + ||\\beta^{\\star}||_1) \\nonumber \\\\\n\u0026amp; \\leq \\frac{||X^\\top \\epsilon||_{\\infty}}{n} (||\\hat{\\beta}||_1 + ||\\beta^{\\star}||_1) + \\lambda_n(||\\beta^{\\star}||_1-||\\hat{\\beta}||_1)\\\\\n\u0026amp; = ||\\hat{\\beta}||_1 {\\underbrace{(\\frac{||X^\\top \\epsilon||_{\\infty}}{n} - \\lambda_n)}_{\\leq 0}} + ||{\\beta}^{\\star}||_1 {\\underbrace{(\\frac{||X^\\top \\epsilon||_{\\infty}}{n} + \\lambda_n)}_{\\leq 2\\lambda_n}} \\\\\n\u0026amp; (\\because \\frac{||X^\\top \\epsilon||_{\\infty}}{n} - \\lambda_n \\leq 0 \\text{ by the condition of the Theorem 1}) \\nonumber\\\\\n\u0026amp; \\leq ||\\beta^{\\star}||_1 \\cdot 2\\lambda_n \\label{eqn:2} \\end{align}\nSo we see the last expression $ \\frac{1}{n} ||X (\\hat{\\beta}-\\beta^{\\star})||_2^2 \\leq 4 ||\\beta^{\\star}||_1 \\lambda_n $. This finishes the proof.\n","date":1606875194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606875194,"objectID":"64b1feccf9416fd0b44fedc1ebad94a6","permalink":"https://jungyeol-kim.github.io/post/lasso/","publishdate":"2020-12-01T21:13:14-05:00","relpermalink":"/post/lasso/","section":"post","summary":"One of the types of errors that we are concerned with in Lasso regression is the prediction loss: $ ||X (\\hat{\\beta}-\\beta^{\\star})||^2_2. $ For the model $ Y=X\\beta^{\\star}+\\epsilon $, where $ \\epsilon \\sim \\text{subG}(\\sigma^2) $, the Lasso solution is","tags":["R","V2V","Network"],"title":"Lasso and Estimation Bound","type":"post"},{"authors":null,"categories":["R"],"content":"Information propagation in V2V-enabled transportation networks is highly influenced by both vehicle mobility and wireless communication. The mobility patterns and communication conditions are not only heterogeneous, but also vary both temporally and spatially. In particular, realistic traffic flow changes with time, exhibiting sharp time-triggered transitions, due to external factors such as traffic lights, unpredictable disruptions (e.g., accidents), and planned disruptions (e.g., road-block). More specifically, traffic signals cause traffic synchronization, due to vehicles stopping during the red phase, and starting almost simultaneously during the green phase, which fundamentally alters the dynamics of V2V message propagation in a complex manner. In this paper, we propose a mathematical framework, starting from a continuous-time Markov chain, that characterizes the fraction of vehicles that have received a message over time and space in an arbitrary road network even when the traffic flow exhibits sharp time-triggered transitions. Our framework can accommodate arbitrary traffic synchronization patterns corresponding for example to the presence of an arbitrary number of traffic signals. The stochastic model for V2V message flow converges to a set of differential equations as the number of vehicles increases. The analytical characterization lends itself to a fast computation regardless of the number of vehicles and traffic synchronization patterns, while vehicular network simulators can only realistically simulate small-scale transportation networks. We find that V2V simulations of a statistical model with traffic synchronization and simulation of communications applied on a synthetic traffic trace well match our model solution.\n   ","date":1606875194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606875194,"objectID":"4d94ed9aafb652f484a60f7441de7acf","permalink":"https://jungyeol-kim.github.io/project/traffic-signal/","publishdate":"2020-12-01T21:13:14-05:00","relpermalink":"/project/traffic-signal/","section":"project","summary":"Information propagation in V2V-enabled transportation networks is highly influenced by both vehicle mobility and wireless communication. The mobility patterns and communication conditions are not only heterogeneous, but also vary both temporally and spatially.","tags":["R","V2V","Network"],"title":"Modeling the Impact of Traffic Signals on V2V Information Flow","type":"project"},{"authors":null,"categories":["R"],"content":"Exploratory Data Analysis We remove $49 $ genes (features) from the raw data since the genes has no value across all samples. We then standardize the data before performing (sparse) principal component analysis. Figure 1 and 2 provide summary statistics. Figure 1 represents the number of samples available for each of the tissues, and Figure 2 represents the number of tissues provided by each of the donors.\n     Throughout this report, we use primary tissues (SMTS) rather than tissues (SMTSD) for simple visualization.\nPrincipal Component Analysis (PCA) We aim to see if the standard PCA can reveal the difference in gene expressions among different tissue types. We first perform PCA and compute the principal components.\nset.seed(2021) pca.results \u0026lt;- irlba::prcomp_irlba(final.data.scale, n=50, center = FALSE, scale. = FALSE) a\u0026lt;-summary(pca.results)$importance[2,1:35] b\u0026lt;-summary(pca.results)$importance[3,1:35] pc_var_expd\u0026lt;-data.frame('PC'=1:length(a), 'pct'=a, 'pct_cum'=b, stringsAsFactors = F) ggplot(data = pc_var_expd, aes(x = as.factor(PC))) + geom_col(aes(y = pct)) + geom_line(aes(y = pct_cum, group = 1)) + geom_hline(yintercept = 0.75, linetype=\u0026quot;dashed\u0026quot;, color = \u0026quot;gray50\u0026quot;, size=0.5) + geom_point(aes(y = pct_cum)) + labs(x = \u0026quot;Principal component\u0026quot;, y = \u0026quot;Proportion of Variance\u0026quot;) + scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75), limits = c(0, 0.755)) + theme_classic() + theme(axis.text.x = element_text(size = 18), axis.title.x=element_text(size=24, face=\u0026quot;bold\u0026quot;)) + theme(axis.text.y = element_text(size = 18), axis.title.y=element_text(size=24, face=\u0026quot;bold\u0026quot;))     We notice is that the first 35 components explains over $75% $ of variance. We can effectively reduce dimensionality from $19248 $ to $35 $ while only loosing about $25% $ of variance. We also notice that we can actually explain over $28% $ of variance with just the first two components and over $26% $ of variance with just the first and the third components. The pairwise scatter plot of principal components are displayed as follows. Figure 4(b) shows that, with only two components, we can clearly see separation of Brain, Pituitary, Blood, and Testis tissues from all others.\ntemp\u0026lt;-data.frame(pca.results$x, 'SMTS'=as.factor(final.data.orig$SMTS), 'SMTSD'=as.factor(final.data.orig$SMTSD)) gg_color_hue \u0026lt;- function(n) { hues = seq(15, 375, length = n + 1) hcl(h = hues, l = 65, c = 100)[1:n] } cols = gg_color_hue(length(levels(temp$SMTS))) fills = gg_color_hue(length(levels(temp$SMTS))) alphas = rep(0.2,length(levels(temp$SMTS))) # SMTS.select\u0026lt;-levels(temp$SMTS) SMTS.select\u0026lt;-c(\u0026quot;Brain\u0026quot;, \u0026quot;Blood\u0026quot;, \u0026quot;Testis\u0026quot;, \u0026quot;Pituitary\u0026quot;) c.color\u0026lt;-which(!levels(temp$SMTS) %in% SMTS.select) cols[c.color]\u0026lt;-\u0026quot;#A5A5A5\u0026quot; fills[c.color]\u0026lt;-\u0026quot;#A5A5A5\u0026quot; alphas[c.color]\u0026lt;-0 means \u0026lt;- temp %\u0026gt;% filter(SMTS %in% SMTS.select) %\u0026gt;% group_by(SMTS) %\u0026gt;% summarise(mean_PC1 = mean(PC1), mean_PC3 = mean(PC3)) ggplot(temp, aes(x = PC1, y = PC3, label = SMTS)) + geom_point(aes(colour = SMTS), size=0.5, alpha=0.7, show.legend = FALSE) + stat_ellipse(aes(fill = SMTS, alpha = SMTS), level = .95, geom = \u0026quot;polygon\u0026quot;, lty=0, show.legend = FALSE) + geom_label(data = means, aes(x = mean_PC1, y = mean_PC3, color = SMTS), show.legend = FALSE) + scale_colour_manual(values=cols) + scale_fill_manual(values=fills) + scale_alpha_manual(values=alphas) + theme_classic() + theme(axis.text.x = element_text(size = 17), axis.title.x=element_text(size=20, face=\u0026quot;bold\u0026quot;)) + theme(axis.text.y = element_text(size = 17), axis.title.y=element_text(size=20, face=\u0026quot;bold\u0026quot;)) @       Sparse PCA Since standard PCA does not impose sparsity constraints on the loadings of principal directions, principal components are usually linear combinations of all input features and the none of the loadings are zero in general as shown in Figure 6. However, in Sparse PCA, principal components are a linear combination of a subset of input features, which provides an improved interpretability of the model. Sparse PCA prevents overfitting in this data where the number of features, $p $, is greater than the number of observations, $N $.\nWe therefore use sparse PCA introduced by [1,2]. This Sparse PCA aims to minimize the following problem: $$\\text{min } f(A,B) = \\frac{1}{2} ||X - XBA^T||^2 + \\alpha ||B||_1 + \\frac{1}{2} \\beta ||B||^2, $$ $$\\text{ subject to } A^T A = I. $$ where the matrix B is the sparse weight (loadings) matrix and A is an orthonormal matrix. This uses the elastic net regularization. The principal components $Z $ are formed as $Z = XB $.\nset.seed(2021) sparsepca.results.0.3 \u0026lt;- sparsepca::rspca(final.data.scale, k=35, alpha=1e-3, beta=1e-3, center = FALSE, scale = FALSE) sparsepca.results.0.4 \u0026lt;- sparsepca::rspca(final.data.scale, k=35, alpha=1e-4, beta=1e-4, center = FALSE, scale = FALSE) pca.results \u0026lt;- irlba::prcomp_irlba(final.data.scale, n=50, center = FALSE, scale. = FALSE) num.zero.0.3\u0026lt;-vector() num.zero.0.4\u0026lt;-vector() num.zero.pca\u0026lt;-vector() num.zero.0.3[1]\u0026lt;-sum(sparsepca.results.0.3$loadings[,1]==0) num.zero.0.4[1]\u0026lt;-sum(sparsepca.results.0.4$loadings[,1]==0) num.zero.pca[1]\u0026lt;-sum(pca.results$rotation[,1]==0) for(i in 2:35){ PCs\u0026lt;-1:i num.zero.0.3[i]\u0026lt;-sum(rowSums(sparsepca.results.0.3$loadings[,PCs])==0) num.zero.0.4[i]\u0026lt;-sum(rowSums(sparsepca.results.0.4$loadings[,PCs])==0) num.zero.pca[i]\u0026lt;-sum(rowSums(pca.results$rotation[,PCs])==0) } plot(1:35, num.zero.0.3, xlab=\u0026quot;Number of Principle Components\u0026quot;, ylab=\u0026quot;Number of Common Features with Zero Coefficients across PC's\u0026quot;, type='o', lty=2, pch=1, cex.lab=1.6, cex.axis=1.3, ylim=c(0,19300)) points(1:35, num.zero.0.4, type='o', lty=3, pch=3, cex.lab=1.6, cex.axis=1.3, ylim=c(0,19300)) points(1:35, num.zero.pca, type='o', lty=1, pch=5, cex.lab=1.6, cex.axis=1.3, ylim=c(0,19300)) abline(h=19248, lty=3) text(25, 18500, labels = \u0026quot;Total number of features p=19248\u0026quot;, cex=1.3) text(25, 13500, labels = expression(paste(\u0026quot;Sparse PCA with \u0026quot;, alpha,\u0026quot;=\u0026quot;,10^-3,\u0026quot;, \u0026quot;, beta,\u0026quot;=\u0026quot;,10^-3)), cex=1.3) text(25, 5000, labels = expression(paste(\u0026quot;Sparse PCA with \u0026quot;, alpha,\u0026quot;=\u0026quot;,10^-4,\u0026quot;, \u0026quot;, beta,\u0026quot;=\u0026quot;,10^-4)), cex=1.3) text(25, 1000, labels = \u0026quot;PCA\u0026quot;, cex=1.3)     Figure 6 confirms that non-negligible number of features have zero coefficient across the principal components. For example, for Sparse PCA under the condition of $\\alpha=10^{-3} $ and $\\beta=10^{-3} $, $11518 $ features out of $p=19248 $ features have zero coefficients across the first $35 $ principal components. The number of features with zero coefficients across the PCs would decrease with the number of PCs, but there is a diminishing return. This indicates that the $11518 $ features are likely to be uninformative. Since $\\alpha $ is a sparsity controlling parameter and $\\beta $ controls the amount of ridge shrinkage, higher values of $\\alpha $ lead to sparser components. Refer to the two different results of sparse PCA with two different parameters in Figure 6.\nWe now plot Sparse PCA (with parameters $\\alpha=10^{-3} $ and $\\beta=10^{-3} $) to see if the Sparse PCA can reveal the difference in gene expressions among different tissue types. Figure 7 shows the pairwise scatter plots of the principal components. We can clearly see separation of Brain, Testis, Pituitary, Skin, Muscle, Heart, Blood Vessel, Nerve, Blood, Liver, Lung, Adipose Tissue, and Spleen tissues from all others.\n   [1] N. B. Erichson, P. Zheng, K. Manohar, S. L. Brunton, J. N. Kutz, and A. Y. Aravkin, ‚ÄúSparse principal component analysis via variable projection,‚Äù SIAM Journal on Applied Mathematics, vol. 80, no. 2, pp. 977‚Äì1002, 2020.\n[2] N. B. Erichson, ‚ÄúSpca via variable projection.‚Äù https://github.com/erichson/spca, 2018.\n","date":1606875194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606875194,"objectID":"a9aa488643554b70b5e10f31940d2320","permalink":"https://jungyeol-kim.github.io/project/ensemble-method/","publishdate":"2020-12-01T21:13:14-05:00","relpermalink":"/project/ensemble-method/","section":"project","summary":"Exploratory Data Analysis We remove $49 $ genes (features) from the raw data since the genes has no value across all samples. We then standardize the data before performing (sparse) principal component analysis.","tags":["R","V2V","Network"],"title":"Predicting whether income exceeds $50K/yr based on census data","type":"project"},{"authors":null,"categories":["R"],"content":"Exploratory Data Analysis We remove $49 $ genes (features) from the raw data since the genes has no value across all samples. We then standardize the data before performing (sparse) principal component analysis. Figure 1 and 2 provide summary statistics. Figure 1 represents the number of samples available for each of the tissues, and Figure 2 represents the number of tissues provided by each of the donors.\n     Throughout this report, we use primary tissues (SMTS) rather than tissues (SMTSD) for simple visualization.\nPrincipal Component Analysis (PCA) We aim to see if the standard PCA can reveal the difference in gene expressions among different tissue types. We first perform PCA and compute the principal components.\nset.seed(2021) pca.results \u0026lt;- irlba::prcomp_irlba(final.data.scale, n=50, center = FALSE, scale. = FALSE) a\u0026lt;-summary(pca.results)$importance[2,1:35] b\u0026lt;-summary(pca.results)$importance[3,1:35] pc_var_expd\u0026lt;-data.frame('PC'=1:length(a), 'pct'=a, 'pct_cum'=b, stringsAsFactors = F) ggplot(data = pc_var_expd, aes(x = as.factor(PC))) + geom_col(aes(y = pct)) + geom_line(aes(y = pct_cum, group = 1)) + geom_hline(yintercept = 0.75, linetype=\u0026quot;dashed\u0026quot;, color = \u0026quot;gray50\u0026quot;, size=0.5) + geom_point(aes(y = pct_cum)) + labs(x = \u0026quot;Principal component\u0026quot;, y = \u0026quot;Proportion of Variance\u0026quot;) + scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75), limits = c(0, 0.755)) + theme_classic() + theme(axis.text.x = element_text(size = 18), axis.title.x=element_text(size=24, face=\u0026quot;bold\u0026quot;)) + theme(axis.text.y = element_text(size = 18), axis.title.y=element_text(size=24, face=\u0026quot;bold\u0026quot;))     We notice is that the first 35 components explains over $75% $ of variance. We can effectively reduce dimensionality from $19248 $ to $35 $ while only loosing about $25% $ of variance. We also notice that we can actually explain over $28% $ of variance with just the first two components and over $26% $ of variance with just the first and the third components. The pairwise scatter plot of principal components are displayed as follows. Figure 4(b) shows that, with only two components, we can clearly see separation of Brain, Pituitary, Blood, and Testis tissues from all others.\ntemp\u0026lt;-data.frame(pca.results$x, 'SMTS'=as.factor(final.data.orig$SMTS), 'SMTSD'=as.factor(final.data.orig$SMTSD)) gg_color_hue \u0026lt;- function(n) { hues = seq(15, 375, length = n + 1) hcl(h = hues, l = 65, c = 100)[1:n] } cols = gg_color_hue(length(levels(temp$SMTS))) fills = gg_color_hue(length(levels(temp$SMTS))) alphas = rep(0.2,length(levels(temp$SMTS))) # SMTS.select\u0026lt;-levels(temp$SMTS) SMTS.select\u0026lt;-c(\u0026quot;Brain\u0026quot;, \u0026quot;Blood\u0026quot;, \u0026quot;Testis\u0026quot;, \u0026quot;Pituitary\u0026quot;) c.color\u0026lt;-which(!levels(temp$SMTS) %in% SMTS.select) cols[c.color]\u0026lt;-\u0026quot;#A5A5A5\u0026quot; fills[c.color]\u0026lt;-\u0026quot;#A5A5A5\u0026quot; alphas[c.color]\u0026lt;-0 means \u0026lt;- temp %\u0026gt;% filter(SMTS %in% SMTS.select) %\u0026gt;% group_by(SMTS) %\u0026gt;% summarise(mean_PC1 = mean(PC1), mean_PC3 = mean(PC3)) ggplot(temp, aes(x = PC1, y = PC3, label = SMTS)) + geom_point(aes(colour = SMTS), size=0.5, alpha=0.7, show.legend = FALSE) + stat_ellipse(aes(fill = SMTS, alpha = SMTS), level = .95, geom = \u0026quot;polygon\u0026quot;, lty=0, show.legend = FALSE) + geom_label(data = means, aes(x = mean_PC1, y = mean_PC3, color = SMTS), show.legend = FALSE) + scale_colour_manual(values=cols) + scale_fill_manual(values=fills) + scale_alpha_manual(values=alphas) + theme_classic() + theme(axis.text.x = element_text(size = 17), axis.title.x=element_text(size=20, face=\u0026quot;bold\u0026quot;)) + theme(axis.text.y = element_text(size = 17), axis.title.y=element_text(size=20, face=\u0026quot;bold\u0026quot;)) @       Sparse PCA Since standard PCA does not impose sparsity constraints on the loadings of principal directions, principal components are usually linear combinations of all input features and the none of the loadings are zero in general as shown in Figure 6. However, in Sparse PCA, principal components are a linear combination of a subset of input features, which provides an improved interpretability of the model. Sparse PCA prevents overfitting in this data where the number of features, $p $, is greater than the number of observations, $N $.\nWe therefore use sparse PCA introduced by [1,2]. This Sparse PCA aims to minimize the following problem: $$\\text{min } f(A,B) = \\frac{1}{2} ||X - XBA^T||^2 + \\alpha ||B||_1 + \\frac{1}{2} \\beta ||B||^2, $$ $$\\text{ subject to } A^T A = I. $$ where the matrix B is the sparse weight (loadings) matrix and A is an orthonormal matrix. This uses the elastic net regularization. The principal components $Z $ are formed as $Z = XB $.\nset.seed(2021) sparsepca.results.0.3 \u0026lt;- sparsepca::rspca(final.data.scale, k=35, alpha=1e-3, beta=1e-3, center = FALSE, scale = FALSE) sparsepca.results.0.4 \u0026lt;- sparsepca::rspca(final.data.scale, k=35, alpha=1e-4, beta=1e-4, center = FALSE, scale = FALSE) pca.results \u0026lt;- irlba::prcomp_irlba(final.data.scale, n=50, center = FALSE, scale. = FALSE) num.zero.0.3\u0026lt;-vector() num.zero.0.4\u0026lt;-vector() num.zero.pca\u0026lt;-vector() num.zero.0.3[1]\u0026lt;-sum(sparsepca.results.0.3$loadings[,1]==0) num.zero.0.4[1]\u0026lt;-sum(sparsepca.results.0.4$loadings[,1]==0) num.zero.pca[1]\u0026lt;-sum(pca.results$rotation[,1]==0) for(i in 2:35){ PCs\u0026lt;-1:i num.zero.0.3[i]\u0026lt;-sum(rowSums(sparsepca.results.0.3$loadings[,PCs])==0) num.zero.0.4[i]\u0026lt;-sum(rowSums(sparsepca.results.0.4$loadings[,PCs])==0) num.zero.pca[i]\u0026lt;-sum(rowSums(pca.results$rotation[,PCs])==0) } plot(1:35, num.zero.0.3, xlab=\u0026quot;Number of Principle Components\u0026quot;, ylab=\u0026quot;Number of Common Features with Zero Coefficients across PC's\u0026quot;, type='o', lty=2, pch=1, cex.lab=1.6, cex.axis=1.3, ylim=c(0,19300)) points(1:35, num.zero.0.4, type='o', lty=3, pch=3, cex.lab=1.6, cex.axis=1.3, ylim=c(0,19300)) points(1:35, num.zero.pca, type='o', lty=1, pch=5, cex.lab=1.6, cex.axis=1.3, ylim=c(0,19300)) abline(h=19248, lty=3) text(25, 18500, labels = \u0026quot;Total number of features p=19248\u0026quot;, cex=1.3) text(25, 13500, labels = expression(paste(\u0026quot;Sparse PCA with \u0026quot;, alpha,\u0026quot;=\u0026quot;,10^-3,\u0026quot;, \u0026quot;, beta,\u0026quot;=\u0026quot;,10^-3)), cex=1.3) text(25, 5000, labels = expression(paste(\u0026quot;Sparse PCA with \u0026quot;, alpha,\u0026quot;=\u0026quot;,10^-4,\u0026quot;, \u0026quot;, beta,\u0026quot;=\u0026quot;,10^-4)), cex=1.3) text(25, 1000, labels = \u0026quot;PCA\u0026quot;, cex=1.3)     Figure 6 confirms that non-negligible number of features have zero coefficient across the principal components. For example, for Sparse PCA under the condition of $\\alpha=10^{-3} $ and $\\beta=10^{-3} $, $11518 $ features out of $p=19248 $ features have zero coefficients across the first $35 $ principal components. The number of features with zero coefficients across the PCs would decrease with the number of PCs, but there is a diminishing return. This indicates that the $11518 $ features are likely to be uninformative. Since $\\alpha $ is a sparsity controlling parameter and $\\beta $ controls the amount of ridge shrinkage, higher values of $\\alpha $ lead to sparser components. Refer to the two different results of sparse PCA with two different parameters in Figure 6.\nWe now plot Sparse PCA (with parameters $\\alpha=10^{-3} $ and $\\beta=10^{-3} $) to see if the Sparse PCA can reveal the difference in gene expressions among different tissue types. Figure 7 shows the pairwise scatter plots of the principal components. We can clearly see separation of Brain, Testis, Pituitary, Skin, Muscle, Heart, Blood Vessel, Nerve, Blood, Liver, Lung, Adipose Tissue, and Spleen tissues from all others.\n   [1] N. B. Erichson, P. Zheng, K. Manohar, S. L. Brunton, J. N. Kutz, and A. Y. Aravkin, ‚ÄúSparse principal component analysis via variable projection,‚Äù SIAM Journal on Applied Mathematics, vol. 80, no. 2, pp. 977‚Äì1002, 2020.\n[2] N. B. Erichson, ‚ÄúSpca via variable projection.‚Äù https://github.com/erichson/spca, 2018.\n","date":1606875194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606875194,"objectID":"8ad42a8c2680b5af93104b31dd390887","permalink":"https://jungyeol-kim.github.io/project/sparse-pca/","publishdate":"2020-12-01T21:13:14-05:00","relpermalink":"/project/sparse-pca/","section":"project","summary":"Exploratory Data Analysis We remove $49 $ genes (features) from the raw data since the genes has no value across all samples. We then standardize the data before performing (sparse) principal component analysis.","tags":["R","V2V","Network"],"title":"Sparse PCA: Dimensionality Reduction for High Dimensional Gene Expression Data","type":"project"},{"authors":null,"categories":["R"],"content":"Traditional contact tracing for COVID-19 tests the direct contacts of those who test positive even if the contacts do not show any symptom. But, by the time an infected individual is tested, the infection starting from the person may have infected a chain of individuals. Hence, why should the testing stop at direct contacts, and not test secondary, tertiary contacts or even contacts further down? One deterrent in testing long chains of individuals right away may be that it substantially increases the testing load, or does it? We investigate the costs and benefits of such multi-hop contact tracing for different number of hops. Considering a large number of contact topologies, spanning synthetic networks of divergent characteristics and those constructed from recorded interactions, we show that the cost-benefit tradeoff can be characterized in terms of a single measurable attribute, the initial epidemic growth rate. Once this growth rate crosses a threshold, multi-hop contact tracing substantially reduces the outbreak size compared to traditional contact tracing. Multi-hop even incurs a lower cost compared to the traditional contact tracing for a large range of values of the growth rate. The cost-benefit tradeoffs and the choice of the number of hops can be classified into three phases, with sharp transitions between them, depending on the value of the growth rate. The need for choosing a larger number of hops becomes greater as the growth rate increases or the environment becomes less conducive toward containing the disease.\n     ","date":1606875194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606875194,"objectID":"ef9f63cda49aa04a5c90046998dcedfd","permalink":"https://jungyeol-kim.github.io/project/contact-tracing/","publishdate":"2020-12-01T21:13:14-05:00","relpermalink":"/project/contact-tracing/","section":"project","summary":"Traditional contact tracing for COVID-19 tests the direct contacts of those who test positive even if the contacts do not show any symptom. But, by the time an infected individual is tested, the infection starting from the person may have infected a chain of individuals.","tags":["R","V2V","Network"],"title":"Tracing and testing multiple generations of contacts to COVID-19 cases: cost-benefit tradeoffs","type":"project"},{"authors":null,"categories":["R"],"content":"V2V technologies bridge two infrastructures: communication and transportation. These infrastructures are interconnected and interdependent. To capture this inter-dependence, which may vary in time and space, we propose a new methodology for modeling information propagation between V2V-enabled vehicles. The model is based on a continuous-time Markov chain which is shown to converge, under appropriate conditions, to a set of clustered epidemiological differential equations. The fraction of vehicles which have received a message, as a function of space and time may be obtained as a solution of these differential equations, which can be solved efficiently, independently of the number of vehicles.\nObjective: Our goal is to model the spread of V2V messages and obatin the fraction of vehicles which have received a message in arbitrary transportation networks, as a function of space and time, using a set of clustered epidemiological differential equations.\nMobility and Communicatoin Networks    As an example, we consider the grid road topology with six avenues and streets. In this network, we assume that all roads are two-way and allow vehicles to move in both directions, and a road segment consists of two clusters corresponding to the opposite directional roads. Since two clusters on the same road segment are sufficiently close to each other, we also assume that the vehicles located in these can communicate; there is an undirected edge between the two clusters on the same road segment.\nUnder these settings, we can create three aforementioned files that are essential for the vehicular messaging simulation using clustered epidemiological differential equations. The files I have already created under these assumptions can be downloaded from the following GitHub repository: https://github.com/jungyeol-kim/V2X-simulations.\nHowever, for any road topologies, vehicle movement patterns, and communication environment, you can use the software code below to automatically generate a set of clustered epidemiological differential equations corresponding to the given conditions, and perform V2V message propagation simulation using the generated differential equations.\nThe following sections describe the software code structure in detail using the sample input files provided based on the above road topology.\nImporting edge list of mobility network We import preset edge list of directed mobility network and corresponding mobility parameter $\\lambda_{ij} $.\nmobility_network\u0026lt;-read.csv(\u0026quot;mobility-network.csv\u0026quot;, header=T, as.is=T) mobility_network$lambda_from_to\u0026lt;-mobility_network$routing_prob*mobility_network$lambda  head(mobility_network) #View(mobility_network)  ## from_clust to_clust routing_prob lambda lambda_from_to ## 1 1 2 0.5 0.05 0.025 ## 2 1 36 0.5 0.05 0.025 ## 3 2 3 0.5 0.05 0.025 ## 4 2 41 0.5 0.05 0.025 ## 5 3 4 0.5 0.05 0.025 ## 6 3 46 0.5 0.05 0.025  Importing edge list of communication network We import preset edge list of undirected communication network and corresponding communication parameter $\\beta_{ij} $.\ncommunication_network\u0026lt;-read.csv(\u0026quot;communication-network.csv\u0026quot;, header=T, as.is=T) communication_network\u0026lt;-communication_network[order(communication_network$cluster_i, communication_network$cluster_j),] rownames(communication_network) \u0026lt;- NULL # reset row names  head(communication_network) #View(communication_network)  ## cluster_i cluster_j beta_ij ## 1 1 1 10 ## 2 1 61 10 ## 3 2 2 10 ## 4 2 62 10 ## 5 3 3 10 ## 6 3 63 10  Defining a neighborhood of a cluster We define a neighborhood of each cluster for both directed mobility network and undirected communication network.\ntotal.clusters\u0026lt;-120 mob.edge.out\u0026lt;-vector(mode='list',length=total.clusters) # outgoing edges from node i in the mobility network mob.edge.out.rate\u0026lt;-vector(mode='list',length=total.clusters) # mobility parameter of outgoing edges from node i in the mobility network mob.edge.in\u0026lt;-vector(mode='list',length=total.clusters) # incoming edges to node i in the mobility network mob.edge.in.rate\u0026lt;-vector(mode='list',length=total.clusters) # mobility parameter of incoming edges from node i in the mobility network comm.edge\u0026lt;-vector(mode='list',length=total.clusters) # undirected edges from or to node i in the communication network comm.edge.rate\u0026lt;-vector(mode='list',length=total.clusters) # communication parameter of undirected edges from or to node i in the communication network for (i in 1:total.clusters) { temp1\u0026lt;-mobility_network[mobility_network$from_clust==i,] temp2\u0026lt;-communication_network[communication_network$cluster_i==i,] mob.edge.out[[i]]\u0026lt;-temp1$to_clust mob.edge.out.rate[[i]]\u0026lt;-temp1$lambda_from_to comm.edge[[i]]\u0026lt;-temp2$cluster_j comm.edge.rate[[i]]\u0026lt;-temp2$beta_ij for(j in 1:length(mob.edge.out[[i]])){ mob.edge.in[[mob.edge.out[[i]][j]]]\u0026lt;-c(mob.edge.in[[mob.edge.out[[i]][j]]],i) mob.edge.in.rate[[mob.edge.out[[i]][j]]]\u0026lt;-c(mob.edge.in.rate[[mob.edge.out[[i]][j]]], mob.edge.out.rate[[i]][j]) } }  Quick exploration of the result\nmob.edge.out[[1]] #View(end point of outgoing edges from a given cluster 1)  ## [1] 2 36  mob.edge.out.rate[[1]] #View(mobility rates corresponding to outgoing edges from a given cluster 1)  ## [1] 0.025 0.025   Endpoints of outgoing edges for a given cluster (vertex) 1 are cluster 2 and 36. Mobility rate from cluster 1 to 2 is 0.25, and mobility rate from 1 to 36 is also 0.25.  mob.edge.in[[7]] #View(mobility_network)  ## [1] 6 36 97  mob.edge.in.rate[[7]] #View(communication_network)  ## [1] 0.01666667 0.01666667 0.01666667   Incoming edges to cluster 7 come from cluster 6, 36, and 97. Mobility rate from cluster 6 to 7 is 0.01666667, mobility rate from 36 to 7 is 0.25, and mobility rate from 97 to 7 is 0.25.  comm.edge[[25]] #View(mobility_network)  ## [1] 25 85  comm.edge.rate[[25]] #View(communication_network)  ## [1] 10 10   Vehicles in cluster 25 can communicate with other vehicles in the same cluster 25, and also communicate with vehicles in cluster 85. (intra- and inter-cluster communication) Intra-cluster communication parameter $\\beta_{25,25} $ is 10, and inter-cluster communication parameter $\\beta_{25,85} = \\beta_{85,25} $ corresponding to communication between cluster 10 and 70 is also 10.  Generation of Differential Equations Recall that under the conditions of our model, for a given choice of initial conditions $\\bigl({\\bf I}(0), {\\bf S}(0)\\bigr) $, the time-evolution, $\\bigl({\\bf I}(t), {\\bf S}(t)\\bigr) $, of the distribution of the asymptotic fraction of informed and non-informed vehicles across clusters is governed by the following system of ordinary differential equations:\n$$\\dot{I}_j(t)=-\\sum_{k\\neq j}^{J} \\lambda^I_{jk}\\left({\\bf{I,S}}\\right) \\cdot I_j + \\sum_{k=1}^{J}\\beta_{kj} \\cdot I_k\\cdot S_j + \\sum_{k\\neq j}^{J} \\lambda^I_{kj}\\left({\\bf{I,S}}\\right)\\cdot I_k \\qquad (j=1,2,\\dots,J), $$ $$ \\dot{S}_j(t)=-\\sum_{k\\neq j}^{J}\\lambda^S_{jk}\\left({\\bf{I,S}}\\right) \\cdot S_j - \\sum_{k=1}^{J}\\beta_{kj} \\cdot I_k \\cdot S_j + \\sum_{k\\neq j}^{J}\\lambda^S_{kj}\\left({\\bf{I,S}}\\right) \\cdot S_k \\qquad (j=1,2,\\dots,J). $$\nWe now create a set of clustered epidemiological differential equations for the given mobility and communicatoin networks. The number of variables and the total number of differential equations are $2J $ each (recall that $J $ is the total number of clusters). The $2J $-dimensional vector $(y_1,y_2,\u0026hellip;,y_J; y_{J+1},y_{J+2},\u0026hellip;,y_{2J})=(I_1,I_2,\u0026hellip;,I_J; S_1,S_2,\u0026hellip;,S_J) $ represent the instantaneous state of the system, semicolon and extra spacing have been added merely for visual separation of informed and non-informed vehicular counts in the various clusters.\nWe create the first summation term on right hand side The first summation terms on the RHS of the $j $ -th equation ($ \\dot{I}_j $) and the $J+j $ -th equation $(\\dot{S}_j) $ is related to the outgoing mobility from cluster $j $.\nmob.out.text\u0026lt;-vector(mode='character',length=total.clusters*2) for(i in 1:total.clusters){ mob.out.text.temp.1\u0026lt;-c(); mob.out.text.temp.2\u0026lt;-c(); mob.out.text.temp.3\u0026lt;-c(); mob.out.text.temp.4\u0026lt;-c() for(j in 1:length(mob.edge.out[[i]])){ mob.out.text.temp.1\u0026lt;-paste(\u0026quot;- \u0026quot;,mob.edge.out.rate[[i]][j],\u0026quot;*y[\u0026quot;,i,\u0026quot;]\u0026quot;, sep=\u0026quot;\u0026quot;) mob.out.text.temp.2\u0026lt;-paste(mob.out.text.temp.2,mob.out.text.temp.1,sep=\u0026quot; \u0026quot;) mob.out.text.temp.3\u0026lt;-paste(\u0026quot;- \u0026quot;,mob.edge.out.rate[[i]][j],\u0026quot;*y[\u0026quot;, total.clusters+i,\u0026quot;]\u0026quot;, sep=\u0026quot;\u0026quot;) mob.out.text.temp.4\u0026lt;-paste(mob.out.text.temp.4,mob.out.text.temp.3,sep=\u0026quot; \u0026quot;) } mob.out.text[i]\u0026lt;-mob.out.text.temp.2 mob.out.text[total.clusters+i]\u0026lt;-mob.out.text.temp.4 }  head(mob.out.text) #View(the first summation term on the RHS of each differential equation)  ## [1] \u0026quot; - 0.025*y[1] - 0.025*y[1]\u0026quot; ## [2] \u0026quot; - 0.025*y[2] - 0.025*y[2]\u0026quot; ## [3] \u0026quot; - 0.025*y[3] - 0.025*y[3]\u0026quot; ## [4] \u0026quot; - 0.025*y[4] - 0.025*y[4]\u0026quot; ## [5] \u0026quot; - 0.05*y[5]\u0026quot; ## [6] \u0026quot; - 0.01666666665*y[6] - 0.01666666665*y[6] - 0.01666666665*y[6]\u0026quot;  We create the second summation term on right hand side The second summation terms on the RHS of the $j $ -th equation ($ \\dot{I}_j $) and the $J+j $ -th equation $(\\dot{S}_j) $ is related to the intra- and inter-communication in cluster $j $.\ncomm.text\u0026lt;-vector(mode='character',length=total.clusters*2) for(i in 1:total.clusters){ comm.text.temp.1\u0026lt;-c(); comm.text.temp.2\u0026lt;-c(); comm.text.temp.3\u0026lt;-c(); comm.text.temp.4\u0026lt;-c() for(j in 1:length(comm.edge[[i]])){ comm.text.temp.1\u0026lt;-paste(comm.edge.rate[[i]][j],\u0026quot;*y[\u0026quot;,comm.edge[[i]][j],\u0026quot;]*y[\u0026quot;, total.clusters+i,\u0026quot;]\u0026quot;, sep=\u0026quot;\u0026quot;) comm.text.temp.2\u0026lt;-paste(comm.text.temp.2,\u0026quot; + \u0026quot;,comm.text.temp.1,sep=\u0026quot;\u0026quot;) comm.text.temp.3\u0026lt;-paste(comm.edge.rate[[i]][j],\u0026quot;*y[\u0026quot;,comm.edge[[i]][j],\u0026quot;]*y[\u0026quot;, total.clusters+i,\u0026quot;]\u0026quot;, sep=\u0026quot;\u0026quot;) comm.text.temp.4\u0026lt;-paste(comm.text.temp.4,\u0026quot; - \u0026quot;,comm.text.temp.3,sep=\u0026quot;\u0026quot;) } comm.text[i]\u0026lt;-comm.text.temp.2 comm.text[total.clusters+i]\u0026lt;-comm.text.temp.4 }  head(comm.text) #View(the second summation term on the RHS of each differential equation)  ## [1] \u0026quot; + 10*y[1]*y[121] + 10*y[61]*y[121]\u0026quot; \u0026quot; + 10*y[2]*y[122] + 10*y[62]*y[122]\u0026quot; ## [3] \u0026quot; + 10*y[3]*y[123] + 10*y[63]*y[123]\u0026quot; \u0026quot; + 10*y[4]*y[124] + 10*y[64]*y[124]\u0026quot; ## [5] \u0026quot; + 10*y[5]*y[125] + 10*y[65]*y[125]\u0026quot; \u0026quot; + 10*y[6]*y[126] + 10*y[66]*y[126]\u0026quot;  We create the third summation term on right hand side The third summation terms on the RHS of the $j $ -th equation ($ \\dot{I}_j $) and the $J+j $ -th equation $(\\dot{S}_j) $ is related to the incoming mobility to cluster $j $\nmob.in.text\u0026lt;-vector(mode='character',length=total.clusters*2) for(i in 1:total.clusters){ mob.in.text.temp.1\u0026lt;-c(); mob.in.text.temp.2\u0026lt;-c(); mob.in.text.temp.3\u0026lt;-c(); mob.in.text.temp.4\u0026lt;-c() for(j in 1:length(mob.edge.in[[i]])){ mob.in.text.temp.1\u0026lt;-paste(mob.edge.in.rate[[i]][j],\u0026quot;*y[\u0026quot;, mob.edge.in[[i]][j],\u0026quot;]\u0026quot;, sep=\u0026quot;\u0026quot;) mob.in.text.temp.2\u0026lt;-paste(mob.in.text.temp.2,\u0026quot; + \u0026quot;,mob.in.text.temp.1,sep=\u0026quot; \u0026quot;) mob.in.text.temp.3\u0026lt;-paste(mob.edge.in.rate[[i]][j],\u0026quot;*y[\u0026quot;, total.clusters+mob.edge.in[[i]][j],\u0026quot;]\u0026quot;, sep=\u0026quot;\u0026quot;) mob.in.text.temp.4\u0026lt;-paste(mob.in.text.temp.4,\u0026quot; + \u0026quot;,mob.in.text.temp.3,sep=\u0026quot; \u0026quot;) } mob.in.text[i]\u0026lt;-mob.in.text.temp.2 mob.in.text[total.clusters+i]\u0026lt;-mob.in.text.temp.4 }  head(mob.in.text) #View(the third summation term on the RHS of each differential equation)  ## [1] \u0026quot; + 0.05*y[91]\u0026quot; \u0026quot; + 0.025*y[1] + 0.025*y[96]\u0026quot; ## [3] \u0026quot; + 0.025*y[2] + 0.025*y[101]\u0026quot; \u0026quot; + 0.025*y[3] + 0.025*y[106]\u0026quot; ## [5] \u0026quot; + 0.025*y[4] + 0.025*y[111]\u0026quot; \u0026quot; + 0.025*y[31] + 0.025*y[92]\u0026quot;  We now combine the all terms to create the complete set of differential equations\ndy\u0026lt;-vector(mode='character',length=total.clusters*2) for (i in 1:(total.clusters*2)) { dy[i]\u0026lt;-paste(\u0026quot;dy\u0026quot;,i,\u0026quot; \u0026lt;- \u0026quot;,mob.out.text[i],mob.in.text[i],comm.text[i],sep=\u0026quot;\u0026quot;) }  head(dy) # View(complete set of differential equations)  ## [1] \u0026quot;dy1 \u0026lt;- - 0.025*y[1] - 0.025*y[1] + 0.05*y[91] + 10*y[1]*y[121] + 10*y[61]*y[121]\u0026quot; ## [2] \u0026quot;dy2 \u0026lt;- - 0.025*y[2] - 0.025*y[2] + 0.025*y[1] + 0.025*y[96] + 10*y[2]*y[122] + 10*y[62]*y[122]\u0026quot; ## [3] \u0026quot;dy3 \u0026lt;- - 0.025*y[3] - 0.025*y[3] + 0.025*y[2] + 0.025*y[101] + 10*y[3]*y[123] + 10*y[63]*y[123]\u0026quot; ## [4] \u0026quot;dy4 \u0026lt;- - 0.025*y[4] - 0.025*y[4] + 0.025*y[3] + 0.025*y[106] + 10*y[4]*y[124] + 10*y[64]*y[124]\u0026quot; ## [5] \u0026quot;dy5 \u0026lt;- - 0.05*y[5] + 0.025*y[4] + 0.025*y[111] + 10*y[5]*y[125] + 10*y[65]*y[125]\u0026quot; ## [6] \u0026quot;dy6 \u0026lt;- - 0.01666666665*y[6] - 0.01666666665*y[6] - 0.01666666665*y[6] + 0.025*y[31] + 0.025*y[92] + 10*y[6]*y[126] + 10*y[66]*y[126]\u0026quot;  dy_name\u0026lt;-c() for (i in 1:(total.clusters*2)) { if(i==1){dy_name\u0026lt;-paste(dy_name,\u0026quot;list(c(dy1\u0026quot;,sep=\u0026quot;\u0026quot;)} else if(i==(total.clusters*2)){dy_name\u0026lt;-paste(dy_name,\u0026quot;,dy\u0026quot;,total.clusters*2,\u0026quot;))}\u0026quot;,sep=\u0026quot;\u0026quot;)} else{dy_name\u0026lt;-paste(dy_name,\u0026quot;,\u0026quot;,paste(\u0026quot;dy\u0026quot;,i,sep=\u0026quot;\u0026quot;),sep=\u0026quot;\u0026quot;)} } set.diff.eqn\u0026lt;-c(\u0026quot;f \u0026lt;- function(t, y, parms) {\u0026quot;,dy,dy_name) write(set.diff.eqn, file = \u0026quot;set_diff_eqn.R\u0026quot;) source(\u0026quot;set_diff_eqn.R\u0026quot;)  Solving Differential Equations Initial condition We import preset initial conditions.\n# import preset initial condition initial_condition\u0026lt;-read.csv(\u0026quot;initial-condition.csv\u0026quot;, header=T, as.is=T) # initial condition: 2J-dimensional vector yini\u0026lt;-c(initial_condition$I_ini,initial_condition$S_ini)  The $2J $ -dimensional vector y_ini represent the state of the system at initial time.\nSolution of differential equations We create a function to encode the set of differential equations in a form suitable for use as the func argument to ode (numerical methods provided by the deSolve package).\nBefore we run, we need to set what are the timestamps used. times denote time sequence for which output is wanted.\nThe example below shows that the result will be generated every step.size=1 time unit, from 0 to sim.time=100 units.\nsim.time\u0026lt;-100 step.size\u0026lt;-1 times \u0026lt;- seq(from = 0, to = sim.time, by = step.size) # output wanted at these time intervals print(times)  ## [1] 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ## [19] 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 ## [37] 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 ## [55] 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 ## [73] 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 ## [91] 90 91 92 93 94 95 96 97 98 99 100  We then compute the fracton of informed vehicles over space and time by applying all into the ODE solver:\nout \u0026lt;- ode(times = times, y=yini, func = f, parms = NULL) # numerically solve the set of # differential equations solution\u0026lt;-out[,-1] rownames(solution)\u0026lt;-times # fraction of informed vehicles per cluster frac.inf.clust\u0026lt;-solution[,1:total.clusters] # fraction of non-informed vehicles per cluster frac.non.inf.clust\u0026lt;-solution[,(1+total.clusters):(2*total.clusters)] colnames(frac.non.inf.clust)\u0026lt;-1:total.clusters write.table(frac.inf.clust, file = \u0026quot;fraction_of_informed_vehicles_per_cluster.csv\u0026quot;, row.names=TRUE,col.names=TRUE, sep=\u0026quot;,\u0026quot;) # export a matrix to a file. write.table(frac.non.inf.clust, file = \u0026quot;fraction_of_non_informed_vehicles_per_cluster.csv\u0026quot;, row.names=TRUE,col.names=TRUE, sep=\u0026quot;,\u0026quot;) # export a matrix to a file.  Row names and Column names of frac.inf.clust and frac.non.inf.clust represent time and cluster respectively. For example, frac.inf.clust[rownames(frac.inf.clust)==10,25] (frac.non.inf.clust[rownames(frac.non.inf.clust)==10,25]) gives the fraction of informed (non-informed) vehicles at $t=10 $ in cluster 25. Naturally, multiplying the matrix frac.inf.clust (frac.non.inf.clust) by the total number of vehicles yields the number of informed (non-informed) vehicles in a given cluster at a given time.\nhead(frac.inf.clust[,1:5]) # View(fraction of informed vehicles at a given time in each cluster)  ## 1 2 3 4 5 ## 0 0.0008333330 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 ## 1 0.0008570283 2.153502e-05 2.742762e-07 3.458794e-09 4.070297e-11 ## 2 0.0008866241 4.467211e-05 1.129462e-06 2.138115e-08 3.472434e-10 ## 3 0.0009224916 6.983034e-05 2.639884e-06 7.020836e-08 1.509739e-09 ## 4 0.0009649812 9.741283e-05 4.886947e-06 1.667595e-07 4.435826e-09 ## 5 0.0010145891 1.280043e-04 8.000834e-06 3.369939e-07 1.088772e-08  We export the results to csv files in the current workspace.\nwrite.table(frac.inf.clust, file = \u0026quot;fraction_of_informed_vehicles_per_cluster.csv\u0026quot;, row.names=TRUE,col.names=TRUE, sep=\u0026quot;,\u0026quot;) # export a matrix to a file. write.table(frac.non.inf.clust, file = \u0026quot;fraction_of_non_informed_vehicles_per_cluster.csv\u0026quot;, row.names=TRUE,col.names=TRUE, sep=\u0026quot;,\u0026quot;) # export a matrix to a file.  Generating Figures Fraction of overall informed vehicles over time To study the degree of information propagation, we plot the fraction of overall vehicles that are informed at time t. A value of 1 on the y axis indicates that all vehicles in the system receive messages via V2V communication.\nfrac.inf.veh\u0026lt;-rowSums(solution[,1:total.clusters]) # fraction of overall vehicles # that are informed over time. plot(times,frac.inf.veh, xlab=\u0026quot;Time\u0026quot;, ylab=\u0026quot;Fraction of informed vehicles\u0026quot;)  Fraction of informed and non-informed vehicles over time per cluster\ncluster.specific\u0026lt;-10 # determine the specific cluster of interest. # fraction of informed vehicles over time in the particular cluster. frac.inf.veh.clust\u0026lt;-frac.inf.clust[,cluster.specific] # fraction of non-informed vehicles over time in the particular cluster. frac.non.inf.veh.clust\u0026lt;-frac.non.inf.clust[,cluster.specific] plot(times, frac.inf.veh.clust, xlab=\u0026quot;Time\u0026quot;, col=\u0026quot;black\u0026quot;, ylab=paste(\u0026quot;Fraction of (non)informed vehicles in cluster \u0026quot;,cluster.specific,sep = \u0026quot;\u0026quot;)) par(new=T) plot(times, frac.non.inf.veh.clust, xlab='', ylab='', col=\u0026quot;red\u0026quot;, axes=F) par(new=F) legend(0, 0.0025, legend=c(\u0026quot;Infomred\u0026quot;,\u0026quot;Non-infomred\u0026quot;), pch = c(1, 1), col=c(\u0026quot;black\u0026quot;,\u0026quot;red\u0026quot;))  [1] Kim, J., Sarkar, S., Venkatesh, S. S., Ryerson, M. S., \u0026amp; Starobinski, D. (2020). An epidemiological diffusion framework for vehicular messaging in general transportation networks. Transportation Research Part B: Methodological, 131, 160-190.\n","date":1606875194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606875194,"objectID":"034c579b06a174f89b1afea8a22b9d94","permalink":"https://jungyeol-kim.github.io/project/v2v/","publishdate":"2020-12-01T21:13:14-05:00","relpermalink":"/project/v2v/","section":"project","summary":"V2V technologies bridge two infrastructures: communication and transportation. These infrastructures are interconnected and interdependent. To capture this inter-dependence, which may vary in time and space, we propose a new methodology for modeling information propagation between V2V-enabled vehicles.","tags":["R","V2V","Network"],"title":"Vehicular Messaging Simulation","type":"project"},{"authors":[""],"categories":null,"content":" Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://jungyeol-kim.github.io/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://jungyeol-kim.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://jungyeol-kim.github.io/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://jungyeol-kim.github.io/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://jungyeol-kim.github.io/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://jungyeol-kim.github.io/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://jungyeol-kim.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]